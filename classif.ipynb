{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример данных о локациях\n",
    "data = {\n",
    "    'latitude': [40.7128, 40.7306, 40.7484, 40.7580, 40.7688, 40.7788, 40.7888, 40.7988],\n",
    "    'longitude': [-74.0060, -73.9352, -73.9857, -73.9857, -73.9681, -73.9581, -73.9481, -73.9381],\n",
    "    'idealness': [1, 1, 0, 0, 0, 0, 0, 0]  # Примерные оценки идеальности (1 - идеальная, 0 - неидеальная)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Создаем трансформер для проекции Меркатора\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3857\", always_xy=True)\n",
    "\n",
    "# Преобразуем географические координаты в плоские\n",
    "df['x'], df['y'] = transformer.transform(df['longitude'].values, df['latitude'].values)\n",
    "\n",
    "# Функция для расчета манхэттенского расстояния\n",
    "def manhattan_distance(x1, y1, x2, y2):\n",
    "    return abs(x2 - x1) + abs(y2 - y1)\n",
    "\n",
    "# Расчет матрицы манхэттенских расстояний\n",
    "def compute_manhattan_distances(df):\n",
    "    n = len(df)\n",
    "    distances = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            distances[i, j] = manhattan_distance(df.loc[i, 'x'], df.loc[i, 'y'], df.loc[j, 'x'], df.loc[j, 'y'])\n",
    "    return distances\n",
    "\n",
    "# Вычисляем матрицу манхэттенских расстояний\n",
    "distances_matrix = compute_manhattan_distances(df)\n",
    "\n",
    "# Добавляем расстояния до всех локаций в качестве признаков\n",
    "distances_df = pd.DataFrame(distances_matrix, columns=[f'distance_to_{j}' for j in range(len(df))])\n",
    "df = pd.concat([df, distances_df], axis=1)\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X = df.drop(columns=['latitude', 'longitude', 'idealness'])\n",
    "y = df['idealness']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Функция для оптимизации гиперпараметров с использованием Optuna\n",
    "def objective(trial, model_type):\n",
    "    if model_type == 'random_forest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = RandomForestClassifier(**params)\n",
    "    elif model_type == 'catboost':\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 50, 200),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-5, 10),\n",
    "            'random_strength': trial.suggest_loguniform('random_strength', 1e-5, 10),\n",
    "            'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.01, 10),\n",
    "            'od_type': 'Iter',\n",
    "            'od_wait': 10,\n",
    "            'verbose': 0,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = CatBoostClassifier(**params)\n",
    "    elif model_type == 'xgboost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "    elif model_type == 'lightgbm':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = LGBMClassifier(**params)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return f1\n",
    "\n",
    "# Оптимизация гиперпараметров для RandomForest\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(lambda trial: objective(trial, 'random_forest'), n_trials=50)\n",
    "best_params_rf = study_rf.best_params\n",
    "print(f\"Лучшие параметры для RandomForest: {best_params_rf}\")\n",
    "\n",
    "# Оптимизация гиперпараметров для CatBoost\n",
    "study_catboost = optuna.create_study(direction='maximize')\n",
    "study_catboost.optimize(lambda trial: objective(trial, 'catboost'), n_trials=50)\n",
    "best_params_catboost = study_catboost.best_params\n",
    "print(f\"Лучшие параметры для CatBoost: {best_params_catboost}\")\n",
    "\n",
    "# Оптимизация гиперпараметров для XGBoost\n",
    "study_xgboost = optuna.create_study(direction='maximize')\n",
    "study_xgboost.optimize(lambda trial: objective(trial, 'xgboost'), n_trials=50)\n",
    "best_params_xgboost = study_xgboost.best_params\n",
    "print(f\"Лучшие параметры для XGBoost: {best_params_xgboost}\")\n",
    "\n",
    "# Оптимизация гиперпараметров для LightGBM\n",
    "study_lightgbm = optuna.create_study(direction='maximize')\n",
    "study_lightgbm.optimize(lambda trial: objective(trial, 'lightgbm'), n_trials=50)\n",
    "best_params_lightgbm = study_lightgbm.best_params\n",
    "print(f\"Лучшие параметры для LightGBM: {best_params_lightgbm}\")\n",
    "\n",
    "# Обучение моделей с лучшими параметрами\n",
    "best_model_rf = RandomForestClassifier(**best_params_rf)\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "\n",
    "best_model_catboost = CatBoostClassifier(**best_params_catboost)\n",
    "best_model_catboost.fit(X_train, y_train)\n",
    "\n",
    "best_model_xgboost = XGBClassifier(**best_params_xgboost)\n",
    "best_model_xgboost.fit(X_train, y_train)\n",
    "\n",
    "best_model_lightgbm = LGBMClassifier(**best_params_lightgbm)\n",
    "best_model_lightgbm.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "y_pred_catboost = best_model_catboost.predict(X_test)\n",
    "y_pred_xgboost = best_model_xgboost.predict(X_test)\n",
    "y_pred_lightgbm = best_model_lightgbm.predict(X_test)\n",
    "\n",
    "# Оцениваем качество моделей\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy для RandomForest с оптимизированными параметрами: {accuracy_rf}\")\n",
    "print(f\"F1-score для RandomForest с оптимизированными параметрами: {f1_rf}\")\n",
    "\n",
    "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
    "f1_catboost = f1_score(y_test, y_pred_catboost)\n",
    "print(f\"Accuracy для CatBoost с оптимизированными параметрами: {accuracy_catboost}\")\n",
    "print(f\"F1-score для CatBoost с оптимизированными параметрами: {f1_catboost}\")\n",
    "\n",
    "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
    "f1_xgboost = f1_score(y_test, y_pred_xgboost)\n",
    "print(f\"Accuracy для XGBoost с оптимизированными параметрами: {accuracy_xgboost}\")\n",
    "print(f\"F1-score для XGBoost с оптимизированными параметрами: {f1_xgboost}\")\n",
    "\n",
    "accuracy_lightgbm = accuracy_score(y_test, y_pred_lightgbm)\n",
    "f1_lightgbm = f1_score(y_test, y_pred_lightgbm)\n",
    "print(f\"Accuracy для LightGBM с оптимизированными параметрами: {accuracy_lightgbm}\")\n",
    "print(f\"F1-score для LightGBM с оптимизированными параметрами: {f1_lightgbm}\")\n",
    "\n",
    "# Кросс-валидация\n",
    "cv_scores_rf = cross_val_score(best_model_rf, X, y, cv=5, scoring='f1')\n",
    "f1_cv_rf = cv_scores_rf.mean()\n",
    "print(f\"F1-score после кросс-валидации для RandomForest: {f1_cv_rf}\")\n",
    "\n",
    "cv_scores_catboost = cross_val_score(best_model_catboost, X, y, cv=5, scoring='f1')\n",
    "f1_cv_catboost = cv_scores_catboost.mean()\n",
    "print(f\"F1-score после кросс-валидации для CatBoost: {f1_cv_catboost}\")\n",
    "\n",
    "cv_scores_xgboost = cross_val_score(best_model_xgboost, X, y, cv=5, scoring='f1')\n",
    "f1_cv_xgboost = cv_scores_xgboost.mean()\n",
    "print(f\"F1-score после кросс-валидации для XGBoost: {f1_cv_xgboost}\")\n",
    "\n",
    "cv_scores_lightgbm = cross_val_score(best_model_lightgbm, X, y, cv=5, scoring='f1')\n",
    "f1_cv_lightgbm = cv_scores_lightgbm.mean()\n",
    "print(f\"F1-score после кросс-валидации для LightGBM: {f1_cv_lightgbm}\")\n",
    "\n",
    "# Предсказываем идеальность для новых локаций\n",
    "new_locations = pd.DataFrame({\n",
    "    'latitude': [40.7530, 40.7688],\n",
    "    'longitude': [-73.9824, -73.9681]\n",
    "})\n",
    "\n",
    "new_locations['x'], new_locations['y'] = transformer.transform(new_locations['longitude'].values, new_locations['latitude'].values)\n",
    "\n",
    "# Вычисляем матрицу манхэттенских расстояний для новых локаций\n",
    "new_distances_matrix = np.zeros((len(new_locations), len(df)))\n",
    "for i in range(len(new_locations)):\n",
    "    for j in range(len(df)):\n",
    "        new_distances_matrix[i, j] = manhattan_distance(new_locations.loc[i, 'x'], new_locations.loc[i, 'y'], df.loc[j, 'x'], df.loc[j, 'y'])\n",
    "\n",
    "# Добавляем расстояния до всех локаций в качестве признаков\n",
    "new_distances_df = pd.DataFrame(new_distances_matrix, columns=[f'distance_to_{j}' for j in range(len(df))])\n",
    "new_locations = pd.concat([new_locations, new_distances_df], axis=1)\n",
    "\n",
    "# Предсказания с использованием RandomForest с оптимизированными параметрами\n",
    "new_locations_pred_rf = best_model_rf.predict(new_locations.drop(columns=['latitude', 'longitude']))\n",
    "print(f\"Предсказанная идеальность для новых локаций с использованием RandomForest с оптимизированными параметрами: {new_locations_pred_rf}\")\n",
    "\n",
    "# Предсказания с использованием CatBoost с оптимизированными параметрами\n",
    "new_locations_pred_catboost = best_model_catboost.predict(new_locations.drop(columns=['latitude', 'longitude']))\n",
    "print(f\"Предсказанная идеальность для новых локаций с использованием CatBoost с оптимизированными параметрами: {new_locations_pred_catboost}\")\n",
    "\n",
    "# Предсказания с использованием XGBoost с оптимизированными параметрами\n",
    "new_locations_pred_xgboost = best_model_xgboost.predict(new_locations.drop(columns=['latitude', 'longitude']))\n",
    "print(f\"Предсказанная идеальность для новых локаций с использованием XGBoost с оптимизированными параметрами: {new_locations_pred_xgboost}\")\n",
    "\n",
    "# Предсказания с использованием LightGBM с оптимизированными параметрами\n",
    "new_locations_pred_lightgbm = best_model_lightgbm.predict(new_locations.drop(columns=['latitude', 'longitude']))\n",
    "print(f\"Предсказанная идеальность для новых локаций с использованием LightGBM с оптимизированными параметрами: {new_locations_pred_lightgbm}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
